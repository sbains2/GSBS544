---
title: GSBS544 Lab 6
author: Sahil Bains
format:
  html:
    embed-resources: true
    code-fold: true
echo: true
---
Github Link: https://github.com/sbains2/GSBS544

```{python}
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import make_column_selector, ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
import math

# Importing the data and doing some checks
df = pd.read_csv('hitters.csv')
df.info()
df.describe()

```


```{python}
# Removing NA's in the salary - dropped about 60 rows
df = df.dropna(subset=['Salary'])
df
```

Part I: Different Model Specs
A. 

i. Regression without regularization
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression

```{python}

# Defining X and y
X = df.drop(columns=['Salary'])
y = df['Salary']

# Defining numeric columns
numeric = X.select_dtypes(include=[np.number]).columns

# Setting up column transformer
ct = ColumnTransformer(
    [ # Dummifying league, division, and new league
        ('dummify', OneHotEncoder(sparse_output=False, drop='first'), ['League', 'Division', 'NewLeague']),
        # Standardizing all numeric variables
        ('standardize', StandardScaler(), numeric)
    ],
    remainder='drop'
)

# Setting up pipeline
pipe = Pipeline(
  [("preprocessing", ct),
  ("linear_regression", LinearRegression())]
)

# Splitting training and testing variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipe.fit(X_train, y_train)

r2 = pipe.score(X_test, y_test)
print(r2)

```

ii. Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.

```{python}
# Fitting pipeline to entire dataset
fitted = pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = fitted.named_steps['linear_regression'].coef_

# Initializing dataframe to put coefficients in
comparing_coeffs = pd.DataFrame()

# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = features
comparing_coeffs["LR"] = coeffs


comparing_coeffs
```

Interpretation:

iii. Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
# Finding cross validation scores - r2 and mse
r2scores = cross_val_score(pipe, X, y, cv=5, scoring='r2')
mse = -cross_val_score(pipe, X, y, cv=5, scoring='neg_mean_squared_error')


print('CV R2 scores:', r2scores.mean(), 'mean squared error:', mse.mean())

```

If we utilized this pipeline, using the current cross validation scores available, we can estimate a MSE of 112677.23, indicating the model error would, on average, give us salary estimates that are $112677.23 off.

B. Ridge regression
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression

```{python}

# Creating a pipeline that performs ordinary ridge regression
ridge_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('ridge_regression', Ridge(alpha=1))
    ]
)

ridge_pipe_fitted = ridge_pipe.fit(X_train, y_train)

```

Use cross-validation to tune the lambda hyperparameter.

```{python}

# Defining the alpha values
alphas = {'ridge_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(ridge_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame(data = {"alphas": np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]), "scores": fitted_grid.cv_results_['mean_test_score']})


```

Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.

```{python}
# Extracting best lambda
best_lambda = fitted_grid.best_params_['ridge_regression__alpha']
best_lambda

ridge_full = fitted_grid.best_estimator_
```

```{python}

# Creating column to see all the features along with the ridge regression coeffiicents
comparing_coeffs['features'] = ridge_full.named_steps['standardizing'].get_feature_names_out()
comparing_coeffs['ridge'] = ridge_full.named_steps['ridge_regression'].coef_

comparing_coeffs
```

In interpreting some of the most important coefficients, we can see that for every 1 increase standard deviation in number of runs in a players career, the salary is expected to increase by $321.88. Another significant factor would be the number of hits in 1986, where every standard deviation increase in the number of hits translates to an increase in the salary by $286.92.

Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = ridge_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```

C. Lasso Regression
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary lasso regression

```{python}
# Creating a pipeline that performs ordinary lasso regression
lasso_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('lasso_regression', Lasso(alpha=1))
    ]
)

lasso_pipe_fitted = lasso_pipe.fit(X_train, y_train)
```

Use cross-validation to tune the lambda hyperparameter.

```{python}

# Defining the alpha values
alphas = {'lasso_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(lasso_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Finding the best estimator for the lasso regression
lasso_best_estimator = fitted_grid.best_params_['lasso_regression__alpha']

# Fitting the lasso pipe to the full dataset
lasso_full = fitted_grid.best_estimator_

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame(data = {"alphas": np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]), "scores": fitted_grid.cv_results_['mean_test_score']})


```

Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.

```{python}
comparing_coeffs
```

```{python}
lasso_coeffs = lasso_full.named_steps['lasso_regression'].coef_

comparing_coeffs['lasso'] = lasso_full.named_steps['lasso_regression'].coef_

comparing_coeffs
```
In interpreting the most important coefficients after fitting a lasso regression, we see that a 1 sd increase in the number of walks that a player has a $9.95 increase in a players salary. In addition to this, for every 1 sd increase in the number of put outs that a player has, a player's salary increases by $7.57.

Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = lasso_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```

D. Elastic Net
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression

```{python}
# Creating a pipeline that performs ordinary elastic regression
elastic_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('elastic_regression', ElasticNet(alpha=1, l1_ratio=0.5))
    ]
)

elastic_pipe_fitted = elastic_pipe.fit(X_train, y_train)

```

Use cross-validation to tune the lambda and alpha hyperparameters.

```{python}

# Defining the alpha and l1_ratio values
tuning = {'elastic_regression__alpha': np.array([1, 0.1, 0.01, 0.001, 0.0001]),
          'elastic_regression__l1_ratio': np.array([0.001, 0.0001, 0.00001, 0.000001, 0.0000001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(elastic_pipe, param_grid=tuning, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame({
    'alpha': fitted_grid.cv_results_['param_elastic_regression__alpha'].astype(float),
    'l1_ratio': fitted_grid.cv_results_["param_elastic_regression__l1_ratio"].astype(float),
    'mean_r2': fitted_grid.cv_results_["mean_test_score"]
}).sort_values('mean_r2', ascending=False)

```

Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.


```{python}

elastic_full = fitted_grid.best_estimator_

comparing_coeffs['elastic'] = elastic_full.named_steps['elastic_regression'].coef_

comparing_coeffs
```

Interpretation:
When interpreting the coefficients for the elastic net regression methods, for every 1 SD increase in the number of putouts that a player has, their salary goes up by $41.04. Additionally, when the number of runs batted increases by 1 SD, we see that a player's salary is expected to increase on average by $35.65.


Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = elastic_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```


Part II. Variable Selection
Based on the above results, decide on:

Which numeric variable is most important.

_Most important numeric variable: Number of putouts that a player has._

Which five numeric variables are most important

_1. Number of hits (Hits)_
_2. Number of times at bat (AtBat)_
_3. Number of runs batted (RBI)_
_4. Number of walks (Walks)_
_5. Number of Put outs (put outs)_

Which categorical variable is most important

_The most important categorical variable is if the player plays in the East division._

For each of the four model specifications, compare the following possible feature sets:

Using only the one best numeric variable.

```{python}
# Running linear regression for only number of putouts a player has

# Defining new X
X = df[['PutOuts']]

# Setting up new column transformer
ct = ColumnTransformer(
    [   # Standardizing all numeric variables
        ('standardize', StandardScaler(), ['PutOuts'])
    ],
    remainder='drop'
)

# Setting up pipeline
lr_pipe = Pipeline(
  [("preprocessing", ct),
  ("linear_regression", LinearRegression())]
)

# Fitting pipeline to entire dataset
lr_fitted = lr_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lr_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lr_fitted.named_steps['linear_regression'].coef_

# Initializing dataframe to put coefficients in
comparing_coeffs = pd.DataFrame()

# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = features
comparing_coeffs["LR"] = coeffs

comparing_coeffs

```

```{python}
# Running ridge regression for only number of putouts a player has

# Setting up pipeline
ridge_pipe = Pipeline(
  [("preprocessing", ct),
  ("ridge_regression", Ridge())]
)

# Defining the alpha values
alphas = {'ridge_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(ridge_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['ridge_regression__alpha']

ridge_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
ridge_fitted = ridge_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = ridge_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = ridge_fitted.named_steps['ridge_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["Ridge"] = coeffs

comparing_coeffs
```

```{python}
# Running lasso regression for only number of putouts a player has

# Setting up pipeline
lasso_pipe = Pipeline(
  [("preprocessing", ct),
  ("lasso_regression", Lasso())]
)

# Defining the alpha values
alphas = {'lasso_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(lasso_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['lasso_regression__alpha']

lasso_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
lasso_fitted = lasso_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lasso_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lasso_fitted.named_steps['lasso_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["Lasso"] = coeffs

comparing_coeffs
```

```{python}
# Running elastic net regression for only number of putouts a player has

# Setting up pipeline
elastic_pipe = Pipeline(
  [("preprocessing", ct),
  ("elastic_regression", ElasticNet())]
)

# Defining the alpha and l1 ratio values
alphas = {'elastic_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]),
         'elastic_regression__l1_ratio': np.array([0.001, 0.0001, 0.00001, 0.000001, 0.0000001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(elastic_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['elastic_regression__alpha']

elastic_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
elastic_fitted = elastic_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = elastic_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = elastic_fitted.named_steps['elastic_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["elastic"] = coeffs

comparing_coeffs
```

Using only the five best variables.

```{python}
# Running linear regression for the best numerical variables.

# Defining new X
X = df[['Hits', 'RBI', 'AtBat', 'Walks', 'PutOuts']]

# Setting up new column transformer
ct = ColumnTransformer(
    [   # Standardizing all numeric variables
        ('standardize', StandardScaler(), ['Hits', 'RBI', 'AtBat', 'Walks', 'PutOuts'])
    ],
    remainder='drop'
)

# Setting up pipeline
lr_pipe = Pipeline(
  [("preprocessing", ct),
  ("linear_regression", LinearRegression())]
)

# Fitting pipeline to entire dataset
lr_fitted = lr_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lr_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lr_fitted.named_steps['linear_regression'].coef_

# Initializing dataframe to put coefficients in
comparing_coeffs = pd.DataFrame()

# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = features
comparing_coeffs["LR"] = coeffs

comparing_coeffs

```

```{python}
# Running ridge regression for for the best numerical variables.

# Setting up pipeline
ridge_pipe = Pipeline(
  [("preprocessing", ct),
  ("ridge_regression", Ridge())]
)


# Defining the alpha values
alphas = {'ridge_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(ridge_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['ridge_regression__alpha']

ridge_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
ridge_fitted = ridge_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = ridge_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = ridge_fitted.named_steps['ridge_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["Ridge"] = coeffs

comparing_coeffs
```

```{python}
# Running lasso regression for for the best numerical variables.


# Setting up pipeline
lasso_pipe = Pipeline(
  [("preprocessing", ct),
  ("lasso_regression", Lasso())]
)


# Defining the alpha values
alphas = {'lasso_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(lasso_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['lasso_regression__alpha']

lasso_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
lasso_fitted = lasso_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lasso_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lasso_fitted.named_steps['lasso_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["Lasso"] = coeffs

comparing_coeffs
```

```{python}
# Running elastic net regression for the best numerical variables.


# Setting up pipeline
elastic_pipe = Pipeline(
  [("preprocessing", ct),
  ("elastic_regression", ElasticNet())]
)

# Defining the alpha and l1 ratio values
alphas = {'elastic_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]),
         'elastic_regression__l1_ratio': np.array([0.001, 0.0001, 0.00001, 0.000001, 0.0000001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(elastic_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['elastic_regression__alpha']

elastic_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
elastic_fitted = elastic_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = elastic_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = elastic_fitted.named_steps['elastic_regression'].coef_

# Formatting coefficients and features in dataframe
comparing_coeffs["elastic"] = coeffs

comparing_coeffs
```


Using the five best numeric variables and their interactions with the one best categorical variable.

```{python}
# Running linear regression for the best numerical variables.

X = df[['Division', 'Hits', 'RBI', 'AtBat', 'Walks', 'PutOuts']]

# Setting up new column transformer
ct = ColumnTransformer(
    [    # Dummifying league, division, and new league
        ('dummify', OneHotEncoder(sparse_output=False, drop='first'), ['Division']),
        # Standardizing all numeric variables
        ('standardize', StandardScaler(), ['Hits', 'RBI', 'AtBat', 'Walks', 'PutOuts']),
    ],
    remainder='drop'
)

# Setting up pipeline
lr_pipe = Pipeline(
  [("preprocessing", ct),
   ('interaction', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
  ("linear_regression", LinearRegression())]
)

# Fitting pipeline to entire dataset
lr_fitted = lr_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lr_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lr_fitted.named_steps['linear_regression'].coef_

# Defining names after categorical and numerical interaction
polynomial = lr_fitted.named_steps['interaction']
polynomial_names = polynomial.get_feature_names_out(features)

# Initializing dataframe to put coefficients in
comparing_coeffs = pd.DataFrame()

# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = polynomial_names
comparing_coeffs["LR"] = coeffs

comparing_coeffs

```

```{python}
# Running ridge regression for the best numerical variables.


# Setting up pipeline
ridge_pipe = Pipeline(
  [("preprocessing", ct),
   ('interaction', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
   ("ridge_regression", Ridge())]
)

# Defining the alpha values
alphas = {'ridge_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(ridge_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['ridge_regression__alpha']

ridge_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
ridge_fitted = ridge_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = ridge_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = ridge_fitted.named_steps['ridge_regression'].coef_

# Defining names after categorical and numerical interaction
polynomial = ridge_fitted.named_steps['interaction']
polynomial_names = polynomial.get_feature_names_out(features)


# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = polynomial_names
comparing_coeffs["Ridge"] = coeffs

comparing_coeffs
```

```{python}
# Running lasso regression for the best numerical variables.


# Setting up pipeline
lasso_pipe = Pipeline(
  [("preprocessing", ct),
   ('interaction', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
  ("lasso_regression", Lasso())]
)


# Defining the alpha values
alphas = {'lasso_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(lasso_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['lasso_regression__alpha']

lasso_pipe = fitted_grid.best_estimator_

# Fitting pipeline to entire dataset
lasso_fitted = lasso_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = lasso_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = lasso_fitted.named_steps['lasso_regression'].coef_

# Defining names after categorical and numerical interaction
polynomial = lasso_fitted.named_steps['interaction']
polynomial_names = polynomial.get_feature_names_out(features)


# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = polynomial_names
comparing_coeffs["Lasso"] = coeffs


comparing_coeffs
```

```{python}
# Running elastic net regression for the best numerical variables.


# Setting up pipeline
elastic_pipe = Pipeline(
  [("preprocessing", ct),
   ('interaction', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
  ("elastic_regression", ElasticNet())]
)

# Defining the alpha and l1 ratio values
alphas = {'elastic_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]),
         'elastic_regression__l1_ratio': np.array([0.001, 0.0001, 0.00001, 0.000001, 0.0000001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(elastic_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

best_alpha = fitted_grid.best_params_['elastic_regression__alpha']

elastic_pipe = fitted_grid.best_estimator_


# Fitting pipeline to entire dataset
elastic_fitted = elastic_pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = elastic_fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = elastic_fitted.named_steps['elastic_regression'].coef_

# Defining names after categorical and numerical interaction
polynomial = elastic_fitted.named_steps['interaction']
polynomial_names = polynomial.get_feature_names_out(features)

# Formatting coefficients and features in dataframe
comparing_coeffs['features'] = polynomial_names
comparing_coeffs["Elastic"] = coeffs

comparing_coeffs

```

Report which combination of features and model performed best, based on the validation metric of MSE.

```{python}



```

(Note: lambda and alpha must be re-tuned for each feature set.)

Part III. Discussion
A. Ridge
Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?

B. LASSO
Compare your LASSO model in I with your three LASSO models in II. Did you get the same 
 results? Why does this make sense? Did you get the same MSEs? Why does this make sense?

C. Elastic Net
Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?

Part IV: Final Model
Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot.