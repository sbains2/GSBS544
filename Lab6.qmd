---
title: GSBS544 Lab 6
author: Sahil Bains
format:
  html:
    embed-resources: true
    code-fold: true
echo: true
---
Github Link: https://github.com/sbains2/GSBS544

```{python}
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import make_column_selector, ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score
import math

# Importing the data and doing some checks
df = pd.read_csv('hitters.csv')
df.info()
df.describe()

```


```{python}
# Removing NA's in the salary - dropped about 60 rows
df = df.dropna(subset=['Salary'])
df
```

Part I: Different Model Specs
A. 

i. Regression without regularization
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression

```{python}

# Defining X and y
X = df.drop(columns=['Salary'])
y = df['Salary']

# Defining numeric columns
numeric = X.select_dtypes(include=[np.number]).columns

# Setting up column transformer
ct = ColumnTransformer(
    [ # Dummifying league, division, and new league
        ('dummify', OneHotEncoder(sparse_output=False), ['League', 'Division', 'NewLeague']),
        # Standardizing all numeric variables
        ('standardize', StandardScaler(), numeric)
    ],
    remainder='drop'
)

# Setting up pipeline
pipe = Pipeline(
  [("preprocessing", ct),
  ("linear_regression", LinearRegression())]
)

# Splitting training and testing variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipe.fit(X_train, y_train)

r2 = pipe.score(X_test, y_test)
print(r2)

```

ii. Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.

```{python}
# Fitting pipeline to entire dataset
fitted = pipe.fit(X,y)

# Getting all the feature names from the fitted column transformer steps - dummify and standardizing variables
features = fitted.named_steps['preprocessing'].get_feature_names_out()

# Getting all the coefficients
coeffs = fitted.named_steps['linear_regression'].coef_

# Initializing dataframe to put coefficients in
comparing_coeffs = pd.DataFrame()

# Formatting coefficients and features in dataframe
comparing_coeffs["coeffs"] = coeffs
comparing_coeffs['features'] = features

comparing_coeffs
```

Interpretation:

iii. Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
# Finding cross validation scores
scores = cross_val_score(fitted, X, y, cv=5, scoring='r2')

# predicting on the fitted model
y_preds = fitted.predict(X_test)

print('CV R2 scores:', scores, 'mean squared error:', mean_squared_error(y_test, y_preds))

```

If we utilized this pipeline, using the current cross validation scores available, we can estimate a MSE of 112677.23, indicating the model error would, on average, give us salary estimates that are $112677.23 off.

B. Ridge regression
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression

```{python}

# Creating a pipeline that performs ordinary ridge regression
ridge_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('ridge_regression', Ridge(alpha=1))
    ]
)

ridge_pipe_fitted = ridge_pipe.fit(X_train, y_train)

```

Use cross-validation to tune the lambda hyperparameter.

```{python}

# Defining the alpha values
alphas = {'ridge_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(ridge_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame(data = {"alphas": np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]), "scores": fitted_grid.cv_results_['mean_test_score']})


```

Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.

```{python}

# Initializing new dataframe
coeffs = pd.DataFrame()

# Creating column to see all the features along with the ridge regression coeffiicents
coeffs['features'] = ridge_pipe_fitted.named_steps['standardizing'].get_feature_names_out()
coeffs['ridge'] = ridge_pipe_fitted.named_steps['ridge_regression'].coef_

coeffs

```

In interpreting some of the most important coefficients, we can see that for every 1 increase standard deviation in number of runs in a players career, the salary is expected to increase by $321.88. Another significant factor would be the number of hits in 1986, where every standard deviation increase in the number of hits translates to an increase in the salary by $286.92.



Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = ridge_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```

C. Lasso Regression
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary lasso regression

```{python}
# Creating a pipeline that performs ordinary lasso regression
lasso_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('lasso_regression', Lasso(alpha=1))
    ]
)

lasso_pipe_fitted = lasso_pipe.fit(X_train, y_train)
```

Use cross-validation to tune the lambda hyperparameter.

```{python}

# Defining the alpha values
alphas = {'lasso_regression__alpha': np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(lasso_pipe, param_grid=alphas, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame(data = {"alphas": np.array([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]), "scores": fitted_grid.cv_results_['mean_test_score']})


```

Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.

```{python}
coeffs['lasso'] = lasso_pipe_fitted.named_steps['lasso_regression'].coef_

```
In interpreting the most important coefficients after fitting a lasso regression, we see that a 1 sd increase in the number of walks that a player has a $9.95 increase in a players salary. In addition to this, for every 1 sd increase in the number of put outs that a player has, a player's salary increases by $7.57.

Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = lasso_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```

D. Elastic Net
Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression

```{python}
# Creating a pipeline that performs ordinary lasso regression
elastic_pipe = Pipeline(
    [
        ('standardizing', ct), # using the original standardizing column transformer
        ('elastic_regression', ElasticNet(alpha=1, l1_ratio=0.5))
    ]
)

elastic_pipe_fitted = elastic_pipe.fit(X_train, y_train)

```

Use cross-validation to tune the lambda and alpha hyperparameters.

```{python}

# Defining the alpha and l1_ratio values
tuning = {'elastic_regression__alpha': np.array([1, 0.1, 0.01, 0.001, 0.0001]),
          'elastic_regression__l1_ratio': np.array([0.001, 0.0001, 0.00001, 0.000001, 0.0000001])}

# Defining the grid search cross validation on the ridge pipeline 
gscv = GridSearchCV(elastic_pipe, param_grid=tuning, cv = 5, scoring='r2')

fitted_grid = gscv.fit(X,y)

# Creating a dataframe of the differing values of alphas and the scores of the fitted grid search cross val scores
pd.DataFrame({
    'alpha': fitted_grid.cv_results_['param_elastic_regression__alpha'].astype(float),
    'l1_ratio': fitted_grid.cv_results_["param_elastic_regression__l1_ratio"].astype(float),
    'mean_r2': fitted_grid.cv_results_["mean_test_score"]
}).sort_values('mean_r2', ascending=False)

```

Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.

```{python}
coeffs['elastic'] = elastic_pipe_fitted.named_steps['elastic_regression'].coef_

coeffs
```

Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}

y_preds = elastic_pipe_fitted.predict(X_test)

print('mean squared error:', mean_squared_error(y_test, y_preds))

```


Part II. Variable Selection
Based on the above results, decide on:

Which numeric variable is most important.

Which five numeric variables are most important

Which categorical variable is most important

For each of the four model specifications, compare the following possible feature sets:

Using only the one best numeric variable.

Using only the five best variables.

Using the five best numeric variables and their interactions with the one best categorical variable.

Report which combination of features and model performed best, based on the validation metric of MSE.

(Note: 
 and 
 must be re-tuned for each feature set.)

Part III. Discussion
A. Ridge
Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?

B. LASSO
Compare your LASSO model in I with your three LASSO models in II. Did you get the same 
 results? Why does this make sense? Did you get the same MSEs? Why does this make sense?

C. Elastic Net
Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?

Part IV: Final Model
Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot.