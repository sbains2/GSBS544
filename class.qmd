---
title: "GSB 544 - Classification Project"
author: "Sahil Bains"
format:
  html:
    embed-resources: true
    code-fold: true
echo: true
---

## Setup

```{python}
# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold
from sklearn.metrics import balanced_accuracy_score, precision_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.inspection import permutation_importance
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.decomposition import PCA

# Load the training and test datasets
train_df = pd.read_csv('classTrain.csv')
test_df = pd.read_csv('classTest.csv')

# Describing the data
print(f"Train shape: {train_df.shape}")
print(f"Test shape: {test_df.shape}")
print(f"\nTarget distribution:\n{train_df['political_affiliation'].value_counts()}")
```

## Preprocessing

```{python}
# Define target variable and features
y = train_df['political_affiliation']
X = train_df.drop(['political_affiliation', 'id_num'], axis=1)

# Separate numeric and categorical columns
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X.select_dtypes(include=['object']).columns.tolist()

print(f"Numeric features: {len(numeric_features)}")
print(f"Categorical features: {len(categorical_features)}")

# Combine transformers into single preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        # Categorical preprocessing: one-hot encode, handle unknown categories in test set
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ])

# Set up 5-fold stratified cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

## Model Training & Evaluation

### 1. Linear Discriminant Analysis (LDA)

```{python}
# Create LDA pipeline with preprocessing
lda_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LinearDiscriminantAnalysis())
])

# Define hyperparameters to tune for LDA
# Using only lsqr solver to avoid eigen solver errors
lda_param_grid = {
    'classifier__solver': ['lsqr'],  # Stable solver that supports shrinkage
    'classifier__shrinkage': [None, 0.1, 0.3, 0.5, 0.7, 0.9, 'auto']  # Regularization strength
}

# Perform grid search with cross-validation
grid_lda = GridSearchCV(lda_pipeline, lda_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)
grid_lda.fit(X, y)

print(f"Best LDA Params: {grid_lda.best_params_}")
print(f"Best LDA CV Score: {grid_lda.best_score_:.4f}")
```

### 2. Quadratic Discriminant Analysis (QDA)

```{python}
# QDA needs dimensionality reduction due to covariance matrix estimation
# Use PCA to reduce features before QDA
qda_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('pca', PCA(random_state=42)),  # Dimensionality reduction
    ('classifier', QuadraticDiscriminantAnalysis())
])

# Tune number of PCA components and QDA regularization
qda_param_grid = {
    'pca__n_components': [5, 10, 15, 20],  # Number of principal components
    'classifier__reg_param': [0.0, 0.1, 0.3, 0.5]  # Regularization parameter
}

# Perform grid search with cross-validation
grid_qda = GridSearchCV(qda_pipeline, qda_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)
grid_qda.fit(X, y)

print(f"Best QDA Params: {grid_qda.best_params_}")
print(f"Best QDA CV Score: {grid_qda.best_score_:.4f}")
```

### 3. Logistic Regression

```{python}
# Create Logistic Regression pipeline
logistic_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

# Tune regularization strength and penalty type
logistic_param_grid = {
    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse regularization strength
    'classifier__penalty': ['l2'],  # L2 (ridge) penalty
    'classifier__solver': ['lbfgs']  # Solver that supports multinomial
}

# Perform grid search with cross-validation
grid_logistic = GridSearchCV(logistic_pipeline, logistic_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)
grid_logistic.fit(X, y)

print(f"Best Logistic Params: {grid_logistic.best_params_}")
print(f"Best Logistic CV Score: {grid_logistic.best_score_:.4f}")
```

### 4. Support Vector Classifier (SVC)

```{python}
# Create SVC pipeline with balanced class weights
svc_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', SVC(class_weight='balanced', random_state=42))
])

# Tune regularization, kernel type, and kernel parameters
svc_param_grid = {
    'classifier__C': [0.1, 1, 10, 100],  # Regularization parameter
    'classifier__gamma': ['scale', 'auto', 0.001, 0.01, 0.1],  # Kernel coefficient
    'classifier__kernel': ['rbf', 'linear', 'poly', 'sigmoid']  # Kernel type
}

# Perform grid search with cross-validation
grid_svc = GridSearchCV(svc_pipeline, svc_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)
grid_svc.fit(X, y)

print(f"Best SVC Params: {grid_svc.best_params_}")
print(f"Best SVC CV Score: {grid_svc.best_score_:.4f}")

# Calculate Balanced Accuracy for Best SVC
svc_balanced_score = cross_val_score(grid_svc.best_estimator_, X, y, cv=cv, scoring='balanced_accuracy', n_jobs=-1).mean()
print(f"Best SVC Balanced Accuracy: {svc_balanced_score:.4f}")

# Calculate Precision for Republican Class
y_pred_svc = cross_val_predict(grid_svc.best_estimator_, X, y, cv=cv, n_jobs=-1)
# Precision for 'Republican' class
prec_republican = precision_score(y, y_pred_svc, labels=['Republican'], average=None)[0]
print(f"Best SVC Precision (Republican): {prec_republican:.4f}")

# Output Confusion Matrix
# Output Confusion Matrix
cm = confusion_matrix(y, y_pred_svc, labels=grid_svc.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_svc.classes_)

disp.plot(cmap='plasma')

# Updated title for dashboard use
plt.title("Model Reliability Across Voter Segments")

plt.show()

# Output Significant Predictors (Permutation Importance)
# Transform data first to get importances for individual one-hot encoded features
X_transformed = grid_svc.best_estimator_[:-1].transform(X)
svc_classifier = grid_svc.best_estimator_.named_steps['classifier']

perm_importance = permutation_importance(svc_classifier, X_transformed, y, n_repeats=10, random_state=42, n_jobs=-1)
svc_feature_names = grid_svc.best_estimator_[:-1].get_feature_names_out()

svc_imp_df = pd.DataFrame({'Feature': svc_feature_names, 'Importance': perm_importance.importances_mean})
print("\n--- Top 10 Significant Predictors (SVC) ---")
print(svc_imp_df.sort_values(by='Importance', ascending=False).head(10))
```

## Model Comparison & Selection

```{python}
# Store all model results in dictionary
results = {
    'LDA': grid_lda.best_score_,
    'QDA': grid_qda.best_score_,
    'Logistic Regression': grid_logistic.best_score_,
    'SVC': grid_svc.best_score_
}

# Display results sorted by performance
print("\nModel Performance:")
for model, score in sorted(results.items(), key=lambda x: x[1], reverse=True):
    print(f"{model:25s}: {score:.4f}")

# Identify the best performing model
best_model_name = max(results, key=results.get)
print(f"\nBest Model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Get the best model's GridSearchCV object
model_map = {
    'LDA': grid_lda,
    'QDA': grid_qda,
    'Logistic Regression': grid_logistic,
    'SVC': grid_svc
}
best_grid = model_map[best_model_name]
```

## Final Prediction

```{python}
# Extract the best model (already fitted on full training data by GridSearchCV)
best_model = best_grid.best_estimator_

# Prepare test features (same columns as training)
X_test = test_df[features]

# Generate predictions on test set
test_predictions = best_model.predict(X_test)

# Display prediction distribution
print(f"\nPrediction distribution:")
print(pd.Series(test_predictions).value_counts())

# Create submission dataframe with correct column names
submission = pd.DataFrame({
    'id_num': test_df['id_num'], 
    'political_affiliation_predicted': test_predictions
})

# Save predictions to CSV file
submission.to_csv('submission.csv', index=False)
print("\nPredictions saved to submission.csv")
print(submission.head(10))
```